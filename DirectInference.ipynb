{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734a4a72-f052-458c-8eb5-d8cf8d65d29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "\n",
    "import time\n",
    "\n",
    "# adjust PyTorch parameter to enable more efficient use of GPU memory\n",
    "import os \n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"backend:native, garbage_collection_threshold:0.6, max_split_size_mb:64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c75cfdb-9dd4-4ae0-85e0-dec15f1e7dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Modules.Models.UNets as UNets\n",
    "import Modules.Data.DICHeLaDataset as DICHeLaSegDataset \n",
    "import Modules.Data.ImageStackTransform as ImageStackTransform  \n",
    "import Modules.TrainAndValidate.LossFunctions as LossFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ead859a-f676-4697-abc1-7017385f8ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## source dataset and model file path configuation\n",
    "test_data_file_path_globs = [\n",
    "    r\"E:\\Python\\DataSet\\TorchDataSet\\DIC-C2DH-HeLa\\Test\\DIC-C2DH-HeLa\\DIC-C2DH-HeLa\\01\\t*.tif\",\n",
    "    r\"E:\\Python\\DataSet\\TorchDataSet\\DIC-C2DH-HeLa\\Test\\DIC-C2DH-HeLa\\DIC-C2DH-HeLa\\02\\t*.tif\",\n",
    "]\n",
    "\n",
    "src_model_path = r\".\\Results\\model_2024-07-07-18-50-42.pt\"\n",
    "# src_model_path = r\".\\Results\\model_2024-07-07-11-16-47.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8664f8-45b4-40ad-a5cc-1219e3d5097b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create necesary data transform\n",
    "data_transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float,scale = False),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e545b2a8-058d-4e21-8612-14e5f8e80e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create data set\n",
    "importlib.reload(DICHeLaSegDataset)\n",
    "\n",
    "color_categories = False\n",
    "\n",
    "test_dataset = DICHeLaSegDataset.DICHeLaWeightedSegDataset(\n",
    "    data_image_path_globs = test_data_file_path_globs,\n",
    "    seg_image_path_globs = None,\n",
    "    data_transform = data_transform,\n",
    "    target_transform = None,\n",
    "    common_transform = None,\n",
    "    color_categories = color_categories,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71ba2e7-3af4-4252-8e79-7a9c90fdcbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create test dataloader for loading data\n",
    "test_batch_size = 1\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                               batch_size = test_batch_size, \n",
    "                                               shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f3ff68-232c-4d73-966e-14f45ea2f1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load model\n",
    "model = torch.load(src_model_path)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77cb066-36dd-4337-978e-da7ecf74efab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use parallel computing if possible\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303fb503-2839-409a-b0c4-757880e23e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Directly use the model to inference\n",
    "check_idx = 0\n",
    "check_batch_idx = 0\n",
    "\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    check_features = None\n",
    "    check_labels = None\n",
    "    check_weights = None\n",
    "\n",
    "    for i_bath in range(check_batch_idx + 1):\n",
    "        check_features, check_labels, check_weights = next(iter(test_dataloader))\n",
    "        \n",
    "    check_features = check_features.to(device)\n",
    "    check_preds = model(check_features)\n",
    "\n",
    "check_features = check_features.detach().cpu()\n",
    "check_preds = check_preds.detach().cpu()\n",
    "check_labels = check_labels.detach().cpu()\n",
    "\n",
    "check_preds = torch.argmax(check_preds, dim = 1)\n",
    "\n",
    "check_feature = check_features[check_idx,...].numpy()\n",
    "check_pred = check_preds[check_idx,...].numpy()\n",
    "\n",
    "check_feature = np.rollaxis(check_feature,0,3)\n",
    "\n",
    "plt.figure(figsize = (9,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(check_feature)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(check_pred)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03886306-6d0c-4ffa-859c-395553c5c0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create destination dir path\n",
    "dst_plot_subdir_path = \".\\Results\\Plots\"\n",
    "\n",
    "if not os.path.isdir(dst_plot_subdir_path):\n",
    "    os.makedirs(dst_plot_subdir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892977df-b916-42ec-b5d3-f5a767c16520",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make nicer picture\n",
    "\n",
    "plot_bkg_color = 0\n",
    "\n",
    "plot_image = check_feature\n",
    "plot_segmentation = check_pred\n",
    "\n",
    "plot_dst_png_file_name = \"NoWeightSegResult.png\"\n",
    "# plot_dst_png_file_name = \"WeightedSegResult.png\"\n",
    "\n",
    "plot_dst_png_file_path = os.path.join(dst_plot_subdir_path, plot_dst_png_file_name)\n",
    "\n",
    "fig = plt.figure(figsize = (13,4))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(plot_image, cmap = \"gray\")\n",
    "plt.colorbar()\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title(\"Input image\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(plot_segmentation, cmap = \"Set3\")\n",
    "plt.colorbar()\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title(\"Segmentation\")\n",
    "\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(plot_image, cmap = \"gray\")\n",
    "plot_labels = np.unique(plot_segmentation[plot_segmentation != plot_bkg_color] )\n",
    "plot_canvas = np.full(plot_segmentation.shape, np.nan)\n",
    "for cur_label in plot_labels:\n",
    "    plot_canvas[plot_segmentation == cur_label] = cur_label\n",
    "plt.imshow(plot_canvas, cmap = \"Set3\", alpha = 0.5)\n",
    "plt.colorbar()\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title(\"Segmentation over input image\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(plot_dst_png_file_path, bbox_inches='tight', dpi = 300)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(plot_dst_png_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99760f0e-0184-4b10-bd4f-9edbe30d3bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
